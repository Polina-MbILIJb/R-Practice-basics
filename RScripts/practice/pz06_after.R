#
# Скрипт для методических указаний к лабораторной работе №3:
#  "Тесты остатков"
#  по дисциплине "Практикум на ЭВМ 4"
#
# Суязова (Аксюк) Светлана Андреевна s.a.askuk@gmail.com
# версия скрипта: 1.0 (15.06.2019)
#
# версия R:
# R.version
#> _                           
#> platform       x86_64-w64-mingw32          
#> arch           x86_64                      
#> os             mingw32                     
#> system         x86_64, mingw32             
#> status                                     
#> major          3                           
#> minor          6.0                         
#> year           2019                        
#> month          04                          
#> day            26                          
#> svn rev        76424                       
#> language       R                           
#> version.string R version 3.6.0 (2019-04-26)
#> nickname       Planting of a Tree 


# Загрузка библиотек
library('lmtest')     # тесты остатков: bptest(), dwtest()
library('broom')      # трансформации данных: augment()
library('car')        # тест на мультиколинеарность: vif()
library('sandwich')   # оценки модели с попракой на гетероскедастичность: vcovHC()



# 1. Импорт данных  ------------------------------------------------------------

# загрузка объектов из сохранённого рабочего пространства
load('Пример_алкоголь_модели.RData')
# просмотр списка объектов
ls()
# названия моделей в списке
names(models.list)



# 2. Графики остатков  ---------------------------------------------------------

#  цикл по моделям в списке models.list
for (i in 1:length(models.list)) {
  # открываем вывод в файл
  png(paste('RPlot', i, '.png', sep = ''), height = 500, width = 500)
  
  # делим полотно на четыре части
  par(mfrow = c(2, 2))
  
  # рисуем 4 графика для одной и той же модели
  plot(models.list[[i]], 1)
  plot(models.list[[i]], 2)
  plot(models.list[[i]], 3)
  plot(models.list[[i]], 5)
  
  # добавляем общий заголовок с названием модели
  mtext(paste('Остатки модели ', names(models.list)[i], sep = ''), 
        side = 3, line = -2, outer = TRUE, cex = 1.2)
  par(mfrow = c(1, 1))
  
  # закрываем вывод в файл
  dev.off()
}

# Регионы с номерами 72 и 8
DF[rownames(DF) %in% c(8, 72), c('Label', 'FO')]

# работаем с четвёртой моделью
# найдём расстояния Кука для влияющих регионов
h <- augment(models.list[[4]], reg.df)
rownames(h) <- rownames(reg.df)
lev <- h[rownames(reg.df) %in% c(8, 72), '.cooksd', drop = F]

# критическая граница F-распределения
n <- nrow(reg.df)
k <- nrow(summary(models.list[[4]])$coeff)
f.tabl <- qf(1 - 0.05, df1 = k, df2 = n - k)

# сравниваем расчётные значения с критической границей
cbind(leverage = round(lev, 2), 
      f.tabl = round(f.tabl, 2), 
      p.val = round(pf(lev$.cooksd, df1 = k, df2 = n - k), 4))



# 3. Проверка равенства среднего остатков нулю  --------------------------------

# номер модели
i <- 4
# t-тест для среднего
t.test(models.list[[i]]$residuals, mu = 0, alternative = 'two.sided')



# 4. Обнаружение гетероскедастичности  -----------------------------------------

# номер модели в списке
i <- 4


# тест Бройша-Пагана ===========================================================
bptest(models.list[[i]])

# добавляем в исходную таблицу h прогнозы, остатки из модели model
h <- augment(models.list[[i]], reg.df)
str(h) # смотрим структуру таблицы h


# тест Уайта ===================================================================
# Во вспомогательной регрессии e^2 зависят от X и X^2
# для моделей 1-2 X: Rural.2011; для моделей 3-4 X: Injury.2011
bptest(models.list[[i]], data = h, 
       varformula = ~ Injury.2011 + I(Injury.2011^2))


# тест Голдфельда-Квандта ======================================================
gqtest(models.list[[i]], order.by = ~ Injury.2011, data = h, fraction = 0.2)


# Тест Глейзера ================================================================
# вектор степеней независимой переменной
beta.vector <- seq(-1, 1.5, by = 0.05)
beta.vector <- beta.vector[beta.vector != 0]

# строим вспомогательные регрессии, и если коэффициент модели 
#  значим, выводим p-значение и степень.
#  для моделей 1-2 X: Rural.2011; для моделей 3-4 X: Injury.2011
for (j in 1:length(beta.vector)) {
  gl.test <- lm(abs(.resid) ~ I(Injury.2011^beta.vector[j]), data = h)
  if (summary(gl.test)$coef[2, 4] < 0.05) {
    print(paste('beta =', beta.vector[j], 
                'p-value =', round(summary(gl.test)$coef[2, 4], 4)))
  }
}



# 5. Обнаружение автокорреляции  -----------------------------------------------

# номер модели в списке
i <- 4

# тест Дарбина-Уотсона на автокорреляцию
dwtest(models.list[[i]], alternative = 'two.sided')

# автокорреляционный коэффициент первого порядка для остатков
n <- nrow(reg.df)
cor.test(x = models.list[[i]]$residuals[1:(n - 1)],
         y = models.list[[i]]$residuals[2:n])



# 6. Переоценка параметров модели с учётом ошибок  -----------------------------

# оценки параметров модели по МНК. для примера: модель 1
i <- 1

# исходные коэффициенты и их стандартные ошибки
coeftest(models.list[[i]])

# робастные оценки стандартных ошибок моделей
# vcovHC(): оценка ковариационной матриц, устойчивая к гетероскедастичности
# vcovHAC(): оценка ковариационной матриц, устойчивая к гетероскедастичности
#  и автокорреляции
coeftest(models.list[[i]], vcov. = vcovHAC(models.list[[i]])) # гетероскедастичность и автокорреляция



# 7. Обнаружение мультиколлинеарности  -----------------------------------------

# VIF-тест на мультиколлинеарность факторов 
#  (ПРИМЕНЯЕТСЯ ДЛЯ МНОЖЕСТВЕННОЙ РЕГРЕССИИ С НЕПРЕРЫВНЫМИ ФАКТОРАМИ)
round(vif(models.list[[2]]), 2)
