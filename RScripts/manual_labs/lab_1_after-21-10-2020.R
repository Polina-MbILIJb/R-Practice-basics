#
# Скрипт для методических указаний к лабораторной работе №1:
#  "Предварительный анализ данных"
#  по дисциплине "Практикум на ЭВМ 4"
#
# Суязова (Аксюк) Светлана Андреевна s.a.askuk@gmail.com
# версия скрипта: 1.0 (15.06.2019)
#
# версия R:
# R.version
# _                           
# platform       x86_64-w64-mingw32          
# arch           x86_64                      
# os             mingw32                     
# system         x86_64, mingw32             
# status                                     
# major          4                           
# minor          0.0                         
# year           2020                        
# month          04                          
# day            24                          
# svn rev        78286                       
# language       R                           
# version.string R version 4.0.0 (2020-04-24)
# nickname       Arbor Day 


# Загрузка библиотек
library('Hmisc')          # для расчёта корреляционной матрицы
library('corrplot')       # визуализация корреляционных матриц: corrplot()
library('nortest')        # для теста Андерсона-Дарлинга ad.test()



# 1. Импорт данных  ------------------------------------------------------------

# проверка содержимого рабочей директории
dir()

# импорт данных из .csv
file.path <- 'https://raw.githubusercontent.com/aksyuk/R-Practice-basics/master/RScripts/manual_labs/%D0%9F%D1%80%D0%B8%D0%BC%D0%B5%D1%80_%D0%B0%D0%BB%D0%BA%D0%BE%D0%B3%D0%BE%D0%BB%D1%8C-2011.csv'
# file.path <- './Пример_алкоголь-2011.csv'
DF <- read.csv2(file.path, stringsAsFactors = F)
    
# размерность фрейма
dim(DF)    
    
# структура фрейма
str(DF)    
    
# делаем из столбца "FO" фактор
DF$FO <- factor(DF$FO)
    
# оставляем только регионы и выбрасываем столбец меток, 
#  чтобы удобнее было считать
reg.df <- DF[DF$Reg.code < 1000, c(-1, -2)]
# выбрасываем пропущенные
reg.df <- na.omit(reg.df)
    
# первые пять строк фрейма
head(reg.df)
# последние пять строк фрейма
tail(reg.df)
    
# 2. Описательные статистики  --------------------------------------------------

# встроенная функция расчёта описательных статистик
summary(reg.df)

# ручной расчёт
#  средние арифметические
mns <- round(apply(reg.df[, -1], 2, mean), 1)
mns

#  стандартные отклонения
sds <- round(apply(reg.df[, -1], 2, sd), 1)
sds

#  коэффициенты вариации
coef.vars <- round(sds / mns * 100, 1)
coef.vars

# делаем свою таблицу только с нужными статистиками 
#  по количественным показателям: среднее, СКО, коэффициент вариации
smm <- rbind(mns, sds, coef.vars)
# названия статистик -- заголовки строк
row.names(smm) <- c('Среднее', 'Стандартное отклонение',
                    'Коэффициент вариации, %')
smm



# 3. Анализ распределения данных  ----------------------------------------------


# Гистограммы ==================================================================

# строим гистограммы на одном полотне 
par(mfrow = c(2, 2))           # разбить полотно на 4 части, 2x2
par(oma = c(0, 0, 1.5, 0))     # внешние поля общего полотна
par(mar = c(4, 4, 0.5, 0.5))   # внутренние поля каждого графика

# цикл по номерам столбцов с количественными переменными
for (i in 2:5) {
    # данные -- i-ый столбец фрейма
    x <- reg.df[, i]
    
    # гистограмма
    hist(x,
         freq = F,            # по вертикали – плотность (доля)
         col = 'wheat',       # цвет заливки
         xlab = colnames(reg.df)[i],     # название оси X – название столбца 
         ylab = 'Плотность',             # название оси Y
         main = '')                      # без заголовка
    
    # теоретическая плотность
    curve(dnorm(x, mean = mean(x), sd = sd(x)), col = 'darkblue', 
          lwd = 2, add = TRUE)
}

# общий заголовок для всех графиков
title(main = 'Гистограммы распределения показателей', 
      outer = TRUE, cex = 1.5)

# вернуть настройки обратно, 1x1
par(mfrow = c(1, 1))


# Тесты на нормальность ========================================================

# тест Шапиро-Уилка на нормальность распределения
#  Retail.Vodka.2011.ps
shapiro.test(reg.df$Retail.Vodka.2011.ps)

# применяем ко всем столбцам с помощью apply()
lapply(reg.df[, 2:5], shapiro.test)

# структура объекта
str(shapiro.test(reg.df$Retail.Vodka.2011.ps))

# применяем ко всем столбцам и вытаскиваем только тестовую статистику
sapply(reg.df[, 2:5], function (x) {
  round(shapiro.test(x)$p.value, 4)
})


# Тест Андерсона-Дарлинга на нормальность распределения
# пример для одного столбца
ad.test(reg.df$Retail.Vodka.2011.ps)



# 4. Анализ линейных взаимосвязей  ---------------------------------------------


# Графики разброса =============================================================

# графики взаимного разброса
pairs(reg.df[, -1],     # фрейм без первого столбца-фактора
      pch = 21,         # тип символов для точек
      col = rgb(0, 0, 1, alpha = 0.4),   # цвет заливки точек
      bg = rgb(0, 0, 1, alpha = 0.4),    # цвет границы точек
      cex = 1.1)                 # масштаб символов для точек


# Корреляционная матрица  ======================================================

# коэффициенты Пирсона с P-значениями
r.corr <- rcorr(as.matrix(reg.df[, -1]))


# Визуализация корреляционной матрицы  =========================================

# сохраняем корреляционную матрицу
matrix.cor <- r.corr$r
    
# сохраняем p-значения
matrix.p <- r.corr$P
    
# изображаем матрицу графически
    corrplot(matrix.cor,          # сама корреляционная матрица
             order = 'original',  # порядок отображения показателей 
             # в матрице
             diag = F,            # не отображать значения на главной 
             # диагонали
             p.mat = matrix.p,    # p-значения
             insig = 'blank',     # метод отображения незначимых
             sig.level = 0.05)    # уровень значимости



# 5. Сохранение рабочего пространства  ------------------------------------------

# список объектов в памяти
ls()

# сохраняем нужные объекты в файл
save(list = c('DF', 'reg.df'), file = './Пример_алкоголь.RData')
# save.image()
# rm()