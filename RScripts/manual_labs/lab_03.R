#
# Скрипт для методических указаний к лабораторной работе №3:
#  "Тесты остатков"
#  по дисциплине "Практикум на ЭВМ 4"
#
# Суязова (Аксюк) Светлана Андреевна s.a.aksuk@gmail.com
# версия скрипта: 1.1 (01.12.2020)
#
# версия R:
# R.version
#> _                           
#> platform       x86_64-w64-mingw32          
#> arch           x86_64                      
#> os             mingw32                     
#> system         x86_64, mingw32             
#> status                                     
#> major          4                           
#> minor          0.3                         
#> year           2020                        
#> month          10                          
#> day            10                          
#> svn rev        79318                       
#> language       R                           
#> version.string R version 4.0.3 (2020-10-10)
#> nickname       Bunny-Wunnies Freak Out 


# Загрузка библиотек
library('lmtest')     # тесты остатков: bptest(), dwtest()
library('broom')      # трансформации данных: augment()
library('car')        # тест на мультиколинеарность: vif()
library('sandwich')   # оценки модели с поправкой на гетероскедастичность: vcovHC()



# 1. Импорт данных  ------------------------------------------------------------

# загрузка объектов из сохранённого рабочего пространства
load('Пример_алкоголь_модели.RData')
# просмотр списка объектов
ls()
# названия моделей в списке
names(models.list)



# 2. Графики остатков  ---------------------------------------------------------

#  цикл по моделям в списке models.list
for (i in 1:length(models.list)) {
    # открываем вывод в файл
    png(paste('RPlot', i, '.png', sep = ''), height = 500, width = 500)
    
    # делим полотно на четыре части
    par(mfrow = c(2, 2))
    
    # рисуем 4 графика для одной и той же модели
    plot(models.list[[i]], 1)
    plot(models.list[[i]], 2)
    plot(models.list[[i]], 3)
    plot(models.list[[i]], 5)
    
    # добавляем общий заголовок с названием модели
    mtext(paste('Остатки модели ', names(models.list)[i], sep = ''), 
          side = 3, line = -2, outer = TRUE, cex = 1.2)
    par(mfrow = c(1, 1))
    
    # закрываем вывод в файл
    dev.off()
}

# Регионы с номерами 72 и 8
DF[rownames(DF) %in% c(8, 72), c('Label', 'FO')]

# работаем с четвёртой моделью
# найдём расстояния Кука для влияющих регионов
h <- augment(models.list[[4]], reg.df)
lev <- h[rownames(reg.df) %in% c(8, 72), '.cooksd', drop = F]

# медианное F-значение - порог для отсечения влияющих
n <- nrow(reg.df)
p <- nrow(summary(fit.X2.fo)$coeff) - 1
f.median <- qf(1 - 0.5, df1 = p, df2 = n - p)
# порог = 1
cut.1 <- 1
# порог = 4 / n
cut.4.n <- round(4 / nrow(reg.df), 2)

# сравниваем расчётные значения с порогами
cbind(leverage = round(lev,2), f.median = round(f.median,2),
      cut.1, cut.4.n)



# 3. Проверка равенства среднего остатков нулю  --------------------------------

# номер модели
i <- 4
# t-тест для среднего
t.test(models.list[[i]]$residuals, mu = 0, alternative = 'two.sided')



# 3. Проверка постоянства среднего остатков ------------------------------------

# номер модели
i <- 4
# первая половина остатков
res.s1 <- fit.X2.fo$residuals[1:(n / 2)]

# вторая половина остатков
res.s2 <- fit.X2.fo$residuals[(n / 2):n]

# t-тест для равенства средних
t.test(res.s1, res.s2, alternative = 'two.sided')



# 4. Обнаружение гетероскедастичности  -----------------------------------------

# номер модели в списке
i <- 4


# тест Бройша-Пагана ===========================================================
bptest(models.list[[i]])

# добавляем в исходную таблицу h прогнозы, остатки из модели model
h <- augment(models.list[[i]], reg.df)
str(h) # смотрим структуру таблицы h


# тест Уайта ===================================================================
# Во вспомогательной регрессии e^2 зависят от X и X^2
# для моделей 1-2 X: Rural.2011; для моделей 3-4 X: Injury.2011
bptest(models.list[[i]], data = h, 
       varformula = ~ Injury.2011 + I(Injury.2011^2))


# тест Голдфельда-Квандта ======================================================
gqtest(models.list[[i]], order.by = ~ Injury.2011, data = h, fraction = 0.2)


# Тест Глейзера ================================================================
# вектор степеней независимой переменной
beta.vector <- seq(-1, 1.5, by = 0.05)
beta.vector <- beta.vector[beta.vector != 0]

# строим вспомогательные регрессии, и если коэффициент модели 
#  значим, выводим p-значение и степень.
#  для моделей 1-2 X: Rural.2011; для моделей 3-4 X: Injury.2011
for (j in 1:length(beta.vector)) {
    gl.test <- lm(abs(.std.resid) ~ I(Injury.2011^beta.vector[j]), data = h)
    if (summary(gl.test)$coef[2, 4] < 0.05) {
        # если найдена значимая модель по тесту Глейзера,
        #  появится сообщение в консоли
        message(paste0('! >>> Модель значима >>> ', 
                      'beta = ', round(beta.vector[j], 2), 
                      'p-value = ', round(summary(gl.test)$coef[2, 4], 4)))
    } else {
        # если модель незначима, тоже пишем в консоль
        message(paste0('Модель для beta = ', round(beta.vector[j], 2), 
                       ' незначима'))
    }
}



# 5. Обнаружение автокорреляции  -----------------------------------------------

# номер модели в списке
i <- 4

# тест Дарбина-Уотсона на автокорреляцию
dwtest(models.list[[i]], alternative = 'two.sided')

# автокорреляционный коэффициент первого порядка для остатков
n <- nrow(reg.df)
cor.test(x = models.list[[i]]$residuals[1:(n - 1)],
         y = models.list[[i]]$residuals[2:n])



# 6. Переоценка параметров модели с учётом ошибок  -----------------------------

# оценки параметров модели по МНК. для примера: модель 1
i <- 1

# исходные коэффициенты и их стандартные ошибки
coeftest(models.list[[i]])

# робастные оценки стандартных ошибок моделей
# vcovHC(): оценка ковариационной матриц, устойчивая к гетероскедастичности
# vcovHAC(): оценка ковариационной матриц, устойчивая к гетероскедастичности
#  и автокорреляции
coeftest(models.list[[i]], vcov. = vcovHAC(models.list[[i]])) # гетероскедастичность и автокорреляция
# NB: сами оценки параметров не меняются,
#  меняются их стандартные ошибки, и выводы по значимости могут измениться



# 7. Обнаружение мультиколлинеарности  -----------------------------------------

# VIF-тест на мультиколлинеарность факторов 
#  NB: применяется для множественной регрессии с непрерывными факторами
round(vif(models.list[[2]]), 2)
